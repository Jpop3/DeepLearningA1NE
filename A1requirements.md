### Requirements for full marks (code)
- [x] More than one hidden layer
- [x] ReLU activation
- [ ] Weight decay - easy, just multiply by a scalar when doing the weight update
- [ ] Momentum in SGD - should be easy - use tutorial
- [ ] Dropout - deactive node with some probability
- [x] Softmax and cross entropy loss - get Seb to do on his own and see the result
- [x] Mini batch training
- [ ] Batch normalisation - extra layer type thing, might be hard
- [ ] Other advanced operations - Adam optimiser is an option, or something else?
- [ ] Runs in feasible time
- [ ] Well organised
- [ ] Instructions on how to run code
- [ ] Latex might get more marks
- [ ] Experiments and results - might need to be able to turn on and off certain aspects, e.g momnetum 
- 

Don'ts
- Badly written code
- Not including instructions of how to run code
- Late submission

### Requirements for Report