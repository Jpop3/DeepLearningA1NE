{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fold', 'hyperparameters', 'train_losses', 'val_losses', 'val_accuracy',\n",
      "       'val_precision', 'val_recall', 'val_f1', 'time_taken',\n",
      "       'early_stop_epoch', 'epochs', 'lr', 'bn', 'batch_size', 'dropout_rate',\n",
      "       'hidden_layers', 'activations', 'input_size', 'weight_decay',\n",
      "       'optimiser', 'early_stopping'],\n",
      "      dtype='object')\n",
      "   fold                                    hyperparameters  \\\n",
      "0     1  {\"epochs\": 50, \"lr\": 0.0001, \"bn\": 0, \"batch_s...   \n",
      "\n",
      "                                        train_losses  \\\n",
      "0  [2.034430485841546, 1.8147283972984134, 1.7246...   \n",
      "\n",
      "                                          val_losses  val_accuracy  \\\n",
      "0  [1.8129982696405291, 1.6970808465567286, 1.639...        0.4986   \n",
      "\n",
      "   val_precision  val_recall    val_f1  time_taken  early_stop_epoch  ...  \\\n",
      "0       0.499073    0.500294  0.494809  158.646537               NaN  ...   \n",
      "\n",
      "       lr  bn  batch_size      dropout_rate      hidden_layers  \\\n",
      "0  0.0001   0           4  [0, 0.1, 0.1, 0]  [128, 64, 32, 10]   \n",
      "\n",
      "                   activations input_size  weight_decay  optimiser  \\\n",
      "0  [None, ReLU, ReLU, softmax]        128             0       Adam   \n",
      "\n",
      "  early_stopping  \n",
      "0   [100, 0.001]  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the CSV file\n",
    "filename = 'best_model_2_fold_details.csv'\n",
    "data = pandas.read_csv(filename)\n",
    "\n",
    "\n",
    "# Split hyperparameters into separate columns from dict, with keys as column names\n",
    "data = data.join(data['Hyperparameters'].apply(eval).apply(pandas.Series))\n",
    "\n",
    "# Convert to dataframe\n",
    "data = pandas.DataFrame(data)\n",
    "\n",
    "# Convert all column names to lower case and remove spaces with _\n",
    "data.columns = data.columns.str.lower().str.replace(' ', '_')\n",
    "print(data.columns)\n",
    "\n",
    "# Apply eval to the train and val losses columns\n",
    "data['train_losses'] = data['train_losses'].apply(eval)\n",
    "data['val_losses'] = data['val_losses'].apply(eval)\n",
    "\n",
    "data_backup = data.copy()\n",
    "\n",
    "print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Add new column for the final validation loss\n",
    "data['final_val_loss'] = data['val_losses'].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.503 & 0.500 & 0.503 & 0.496 & 1.418 & 162.518 & {\"epochs\": 50, \"lr\": 0.0001, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0, 0.1, 0.1, 0], \"hidden_layers\": [128, 64, 32, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.485 & 0.491 & 0.485 & 0.480 & 1.449 & 157.018 & {\"epochs\": 50, \"lr\": 0.0005, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0, 0.1, 0.1, 0], \"hidden_layers\": [128, 64, 32, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.443 & 0.451 & 0.443 & 0.433 & 1.583 & 158.382 & {\"epochs\": 50, \"lr\": 0.001, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0, 0.1, 0.1, 0], \"hidden_layers\": [128, 64, 32, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.098 & 0.010 & 0.100 & 0.018 & 2.309 & 161.518 & {\"epochs\": 50, \"lr\": 0.005, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0, 0.1, 0.1, 0], \"hidden_layers\": [128, 64, 32, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.101 & 0.010 & 0.100 & 0.018 & 2.316 & 159.919 & {\"epochs\": 50, \"lr\": 0.01, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0, 0.1, 0.1, 0], \"hidden_layers\": [128, 64, 32, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.491 & 0.488 & 0.491 & 0.484 & 1.451 & 65.553 & {\"epochs\": 20, \"lr\": 0.0001, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0, 0.1, 0.1, 0], \"hidden_layers\": [128, 64, 32, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.505 & 0.501 & 0.506 & 0.497 & 1.415 & 159.359 & {\"epochs\": 50, \"lr\": 0.0001, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0, 0.1, 0.1, 0], \"hidden_layers\": [128, 64, 32, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.508 & 0.504 & 0.508 & 0.501 & 1.403 & 310.907 & {\"epochs\": 100, \"lr\": 0.0001, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0, 0.1, 0.1, 0], \"hidden_layers\": [128, 64, 32, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.473 & 0.471 & 0.473 & 0.466 & 1.485 & 120.776 & {\"epochs\": 50, \"lr\": 0.0001, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0.0, 0.0, 0.0, 0.0], \"hidden_layers\": [128, 32, 16, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n",
      "0.428 & 0.420 & 0.428 & 0.416 & 1.600 & 107.144 & {\"epochs\": 50, \"lr\": 0.0001, \"bn\": 0, \"batch_size\": 4, \"dropout_rate\": [0.0, 0.0, 0.0, 0.0], \"hidden_layers\": [128, 16, 8, 10], \"activations\": [\"None\", \"ReLU\", \"ReLU\", \"softmax\"], \"input_size\": 128, \"weight_decay\": 0, \"optimiser\": \"Adam\", \"early_stopping\": [100, 0.001]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For each 10 rows/folds representing one model, calulate and store the mean of the val_accuracy, val_precision, val_recall, val_f1, val_loss, time_taken of the folds\n",
    "metrics_dict = {}\n",
    "for i in range(0, len(data), 10):\n",
    "    model_hyperparameters = data.iloc[i]['hyperparameters']\n",
    "    val_accuracy = np.mean(data.iloc[i:i+10]['val_accuracy'])\n",
    "    val_precision = np.mean(data.iloc[i:i+10]['val_precision'])\n",
    "    val_recall = np.mean(data.iloc[i:i+10]['val_recall'])\n",
    "    val_f1 = np.mean(data.iloc[i:i+10]['val_f1'])\n",
    "    val_loss = np.mean(data.iloc[i:i+10]['final_val_loss'])\n",
    "    time_taken = np.mean(data.iloc[i:i+10]['time_taken'])\n",
    "    print(f'{val_accuracy:.3f} & {val_precision:.3f} & {val_recall:.3f} & {val_f1:.3f} & {val_loss:.3f} & {time_taken:.3f} & {model_hyperparameters}')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
